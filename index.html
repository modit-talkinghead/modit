<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="description" content="MoDiT: A novel framework combining 3DMM with a Diffusion-based Transformer for audio-driven talking head generation.">
  <meta name="keywords" content="MoDiT, Talking Head Generation, Diffusion Transformer, 3DMM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MoDiT: Learning Highly Consistent 3D Motion Coefficients</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wangandyyucheng.github.io/">Yucheng Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.danxurgb.net/">Dan Xu</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology</span>
          </div>

          <div class="publication-links">
            <!-- arXiv Link -->
            <span class="link-block">
              <a href="https://arxiv.org/abs/xxxx.xxxxx"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- Code Link -->
            <span class="link-block">
              <a href="https://github.com/dummy/modit"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <!-- Video Link -->
            <span class="link-block">
              <a href="./static/videos/modit_demo.mp4"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Teaser.png" alt="Teaser Image" style="width: 100%; height: auto;">
      <h2 class="content has-text-centered">
        MoDiT combines 3DMM with a Diffusion-based Transformer to generate realistic talking heads from audio with single image.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Audio-driven talking head generation is critical for applications such as virtual assistants, video games, and films. Despite progress in this field, challenges remain in producing both consistent and realistic facial animations. Existing methods face three major limitations:
          </p>
          <ul>
            <li>Temporal jittering caused by weak temporal constraints, resulting in frame inconsistencies.</li>
            <li>Identity drift due to insufficient 3D information, leading to poor facial identity preservation.</li>
            <li>Unnatural blinking behavior due to inadequate modeling of realistic blink dynamics.</li>
          </ul>
          <p>
            To address these issues, we propose MoDiT, a novel framework that combines the 3D Morphable Model (3DMM) with a Diffusion-based Transformer. Our contributions include:
          </p>
          <ul>
            <li>A hierarchical denoising strategy with revised temporal attention and biased self/cross-attention mechanisms, enabling the model to refine lip synchronization and progressively enhance full-face coherence, effectively mitigating temporal jittering.</li>
            <li>The integration of 3DMM coefficients to provide explicit spatial constraints, ensuring accurate 3D-informed optical flow prediction and improved lip synchronization using Wav2Lip results, thereby preserving identity consistency.</li>
            <li>A refined blinking strategy to model natural eye movements, with smoother and more realistic blinking behaviors.</li>
          </ul>
        </div>
      </div>
    </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Methods</h2>
    <div class="columns is-centered is-multiline">
      <!-- Larger Image -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Pipeline.png" alt="Pipeline Image" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
      <!-- Text styled like Abstract -->
      <div class="column is-four-fifths has-text-justified">
        <p class="content has-text-centered">
          Overview of the Diffusion Transformer Pipeline with temporal and spatial condition injection.
        </p>
      </div>
      <!-- Larger Image -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Transformer.png" alt="Transformer Image" style="width: 65%; height: auto; max-width: 1200px;">
      </div>
      <!-- Text styled like Abstract -->
      <div class="column is-four-fifths has-text-justified">
        <p class="content has-text-centered">
          Illustration of structure details of the Transformer Block.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Experiment</h2>
    <div class="columns is-centered is-multiline">
      <!-- Larger Comparison Images -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Compare.png" alt="Comparison Chart" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
      <!-- Text styled like Abstract -->
      <div class="column is-four-fifths has-text-justified">
        <p class="content has-text-centered">
          Comparison with the state-of-the-art lip-syncing methods.
        </p>
      </div>
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Table.png" alt="Comparison Table" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
      <!-- Text styled like Abstract -->
      <div class="column is-four-fifths has-text-justified">
        <p class="content has-text-centered">
          Comparison with the state-of-the-art methods on HDTF and VFHQ dataset.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/1.mp4" type="video/mp4">
        </video>
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/2.mp4" type="video/mp4">
        </video>
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/3.mp4" type="video/mp4">
        </video>
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/4.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{modit2025,
  author    = {Yucheng Wang and Dan Xu},
  title     = {MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation},
  journal   = {arXiv preprint arXiv:xxxx.xxxxx},
  year      = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Source code for this website is based on the <a href="https://nerfies.github.io/">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>