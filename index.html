<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="description" content="MoDiT: A novel framework combining 3DMM with a Diffusion-based Transformer for audio-driven talking head generation.">
  <meta name="keywords" content="MoDiT, Talking Head Generation, Diffusion Transformer, 3DMM">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MoDiT: Learning Highly Consistent 3D Motion Coefficients</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#">
        <span class="icon">
          <i class="fas fa-home"></i>
        </span>
      </a>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://wangandyyucheng.github.io/">Yucheng Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://www.danxurgb.net/">Dan Xu</a><sup>1</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>The Hong Kong University of Science and Technology</span>
          </div>

          <div class="publication-links">
            <!-- arXiv Link -->
            <span class="link-block">
              <a href="https://arxiv.org/abs/xxxx.xxxxx"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
            </span>
            <!-- Code Link -->
            <span class="link-block">
              <a href="https://github.com/dummy/modit"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-github"></i>
                </span>
                <span>Code</span>
              </a>
            </span>
            <!-- Video Link -->
            <span class="link-block">
              <a href="./static/videos/modit_demo.mp4"
                 class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="fab fa-youtube"></i>
                </span>
                <span>Video</span>
              </a>
            </span>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="./static/images/Teaser.png" alt="Teaser Image" style="width: 100%; height: auto;">
      <h2 class="subtitle has-text-centered">
        MoDiT combines 3DMM with a Diffusion-based Transformer to generate realistic talking head animations from audio with single image.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Audio-driven talking head generation is critical for applications such as virtual assistants, video games, and films, where natural lip movements are essential. Despite progress in this field, challenges remain in producing both consistent and realistic facial animations. Existing methods, often based on GANs or UNet-based diffusion models, face three major limitations:
          </p>
          <ol>
            <li>Temporal jittering caused by weak temporal constraints, resulting in frame inconsistencies.</li>
            <li>Identity drift due to insufficient 3D information extraction, leading to poor preservation of facial identity.</li>
            <li>Unnatural blinking behavior due to inadequate modeling of realistic blink dynamics.</li>
          </ol>
          <p>
            To address these issues, we propose MoDiT, a novel framework that combines the 3D Morphable Model (3DMM) with a Diffusion-based Transformer. Our contributions include:
          </p>
          <ol>
            <li>A hierarchical denoising strategy with revised temporal attention and biased self/cross-attention mechanisms, enabling the model to refine lip synchronization and progressively enhance full-face coherence, effectively mitigating temporal jittering.</li>
            <li>The integration of 3DMM coefficients to provide explicit spatial constraints, ensuring accurate 3D-informed optical flow prediction and improved lip synchronization using Wav2Lip results, thereby preserving identity consistency.</li>
            <li>A refined blinking strategy to model natural eye movements, with smoother and more realistic blinking behaviors.</li>
          </ol>
        </div>
      </div>
    </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-four-fifths has-text-centered">
        <h2 class="title is-3">Demo Video</h2>
        <video controls autoplay muted loop playsinline style="width: 100%; height: auto;">
          <source src="./static/videos/Video Demo.mp4" type="video/mp4">
        </video>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Overview of the Diffusion Transformer Pipeline</h2>
    <div class="columns is-centered is-multiline">
      <!-- Larger Image -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Pipeline.png" alt="Pipeline Image" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
      <!-- Text styled like Abstract -->
      <div class="column is-four-fifths has-text-justified">
        <p class="content is-size-5">
          Overview of the Diffusion Transformer Pipeline, showcasing the denoising stages with temporal and spatial condition injection. The integration of 3DMM coefficients to provide explicit spatial constraints, ensuring accurate 3D-informed optical flow prediction and improved lip synchronization. We also employ a hierarchical denoising strategy with revised temporal attention and biased self/cross-attention mechanisms, enabling the model to refine lip synchronization and progressively enhance full-face coherence, effectively mitigating temporal jittering.
        </p>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <h2 class="title is-3 has-text-centered">Comparison</h2>
    <div class="columns is-centered is-multiline">
      <!-- Larger Comparison Images -->
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Compare.png" alt="Comparison Chart" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
      <div class="column is-four-fifths has-text-centered">
        <img src="./static/images/Table.png" alt="Comparison Table" style="width: 100%; height: auto; max-width: 1200px;">
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{modit2025,
  author    = {Yucheng Wang and Dan Xu},
  title     = {MoDiT: Learning Highly Consistent 3D Motion Coefficients with Diffusion Transformer for Talking Head Generation},
  journal   = {arXiv preprint arXiv:xxxx.xxxxx},
  year      = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <p>
        This website is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">Creative Commons Attribution-ShareAlike 4.0 International License</a>.
      </p>
      <p>
        Source code for this website is based on the <a href="https://nerfies.github.io/">Nerfies</a>.
      </p>
    </div>
  </div>
</footer>

</body>
</html>